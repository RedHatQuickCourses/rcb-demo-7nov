#  Setting up an Ansible Control Node and Managed Hosts

[[setting-up-ansible-nodes]]
= Setting Up an Ansible Control Node and Managed Hosts

This section guides you through the process of setting up your fundamental Ansible environment. This includes configuring an *Ansible Control Node* (where Ansible runs) and one or more *Managed Hosts* (the machines Ansible automates). This foundational setup is crucial for any automation tasks you'll perform with Ansible.

[[what-are-control-and-managed-nodes]]
== Understanding Control Nodes and Managed Hosts

Before we dive into the practical setup, let's clearly define these core components in the Ansible ecosystem:

*   **Control Node (or Management Host)**:
    *   This is the machine where Ansible is installed.
    *   You execute all Ansible commands, playbooks, and scripts from this machine.
    *   It acts as the central point for managing your infrastructure.
    *   The Control Node initiates connections and pushes configurations to Managed Hosts.

*   **Managed Host (or Target Host)**:
    *   These are the servers, network devices, or cloud instances that Ansible manages and configures.
    *   Crucially, Managed Hosts do *not* require Ansible software to be installed on them.
    *   They only need a standard operating system, an SSH server (for Linux/Unix), and typically Python (for executing Ansible modules). For Windows hosts, WinRM (Windows Remote Management) is used instead of SSH.

image::ansible-control-node-managed-hosts.png[Ansible Control Node and Managed Hosts Interaction, align=center]

[[prerequisites]]
== Prerequisites for Setup

To successfully follow the hands-on lab and set up your environment, ensure you have the following:

*   **Two Virtual Machines (VMs) or Cloud Instances**:
    *   One VM will serve as your *Control Node*.
    *   One VM will serve as your *Managed Host*.
    *   Both VMs should be running a recent Linux distribution (e.g., Ubuntu Server 22.04 LTS, CentOS Stream 9).
    *   Record their IP addresses for later use.
*   **`sudo` Privileges**: You need a user account with `sudo` privileges on both the Control Node and Managed Hosts.
*   **Internet Connectivity**: Both nodes require internet access to download necessary packages.
*   **Basic Linux Command Line Knowledge**: Familiarity with navigating the file system, editing files, and executing commands in a Linux terminal.

[[control-node-setup]]
== Setting Up the Ansible Control Node

The Control Node is where Ansible is installed and configured to orchestrate your automation tasks.

=== Step 1: Install Ansible on the Control Node

Ansible can be installed using various methods. For most Linux distributions, the system's package manager or `pip` (Python's package installer) are the most common approaches. We'll focus on package managers for simplicity, highlighting Ubuntu/Debian and CentOS/RHEL.

==== Using System Package Manager (Recommended for beginners)

This method typically installs a stable, well-tested version of Ansible that integrates well with your system.

*   **On Ubuntu/Debian-based systems** (e.g., Ubuntu, Debian, Linux Mint):
    The recommended way to install the latest stable version of Ansible is via its official PPA (Personal Package Archive).
    ```bash
    $ sudo apt update
    $ sudo apt install software-properties-common -y
    $ sudo add-apt-repository --yes --update ppa:ansible/ansible
    $ sudo apt install ansible -y
    ```
    Alternatively, for a quick install (which might install an older version from the default repositories):
    ```bash
    $ sudo apt update
    $ sudo apt install ansible -y
    ```

*   **On CentOS/RHEL/Fedora-based systems** (e.g., CentOS Stream, Rocky Linux, AlmaLinux, Fedora):
    For CentOS/RHEL, Ansible is available from the EPEL (Extra Packages for Enterprise Linux) repository. For Fedora, it's usually in the default repositories.
    ```bash
    # For Fedora 30+
    $ sudo dnf install ansible -y

    # For CentOS/RHEL 7, 8, 9 (requires EPEL repository)
    $ sudo yum install epel-release -y # Install EPEL repository first
    $ sudo yum install ansible -y
    ```

==== Using `pip` (Python Package Installer)

This method ensures you get the absolute latest version of Ansible. It's often preferred for developers or when specific Ansible versions are required.

First, ensure Python 3 and `pip` are installed on your system:
```bash
# On Ubuntu/Debian
$ sudo apt update && sudo apt install python3 python3-pip -y

# On CentOS/RHEL/Fedora
$ sudo yum install python3 python3-pip -y # or dnf for Fedora
```
Then, install Ansible using `pip`:
```bash
$ pip3 install --user ansible
```
If you used `pip`, you might need to add `~/.local/bin` to your `PATH` environment variable so your shell can find the `ansible` command. Add the following line to your `~/.bashrc` (or `~/.zshrc`) file and then `source` it:
```bash
$ echo 'export PATH="$HOME/.local/bin:$PATH"' >> ~/.bashrc
$ source ~/.bashrc
```

=== Step 2: Verify Ansible Installation

After installation, it's crucial to verify that Ansible is installed correctly and check its version.
```bash
$ ansible --version
```
You should see output similar to this, indicating the Ansible version, Python location, and configuration details:
```
ansible [core 2.15.x]
  config file = /etc/ansible/ansible.cfg
  configured module search path = ['/home/user/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python location = /usr/bin/python3
  ansible collection location = /home/user/.ansible/collections:/usr/share/ansible/collections
  [...]
```

[[managed-host-setup]]
== Preparing the Managed Host(s)

Preparing Managed Hosts is generally simpler as they do not require Ansible itself to be installed. They primarily need an SSH server and a Python interpreter.

=== Step 1: Ensure SSH Server is Installed and Running

Ansible communicates with Linux Managed Hosts over SSH. Most Linux distributions come with `openssh-server` pre-installed or readily available.

*   **On Ubuntu/Debian-based systems**:
    ```bash
    $ sudo apt update
    $ sudo apt install openssh-server -y
    $ sudo systemctl enable --now ssh # Ensure it starts on boot and is currently running
    ```

*   **On CentOS/RHEL/Fedora-based systems**:
    ```bash
    $ sudo yum install openssh-server -y # or dnf for Fedora
    $ sudo systemctl enable --now sshd # Ensure it starts on boot and is currently running
    # If your firewall is active (e.g., firewalld), allow SSH traffic:
    $ sudo firewall-cmd --permanent --add-service=ssh
    $ sudo firewall-cmd --reload
    ```

=== Step 2: Ensure Python is Installed

Ansible modules, which are the actual code executed on managed hosts to perform tasks, are primarily written in Python. Ansible will automatically attempt to locate a suitable Python interpreter (preferably Python 3) on the managed host.

*   **On most modern Linux systems, Python 3 is already present.** If not, you can install it:
    ```bash
    $ sudo apt update && sudo apt install python3 -y # Ubuntu/Debian
    $ sudo yum install python3 -y # CentOS/RHEL/Fedora
    ```
    xref:ansible-inventory.adoc#ansible-python-interpreter[Later, you can explicitly tell Ansible which Python interpreter to use in your inventory file.]

[[ssh-key-based-authentication]]
== Setting Up SSH Key-Based Authentication

For secure and passwordless communication, Ansible heavily relies on SSH key-based authentication. This mechanism allows the Control Node to connect to Managed Hosts without requiring a password each time, which is essential for automation.

=== Step 1: Generate SSH Key Pair on the Control Node

If you don't already have an SSH key pair (typically `id_rsa` for the private key and `id_rsa.pub` for the public key) on your Control Node, generate one:

```bash
$ ssh-keygen -t rsa -b 4096
```
*   When prompted for the file in which to save the key, press `Enter` to accept the default location (`~/.ssh/id_rsa`).
*   You'll then be asked for a passphrase. For automation scripts, it's common to leave this blank (press `Enter` twice) to enable passwordless access. However, for higher security, setting a strong passphrase is recommended, which would then require `ssh-agent` to manage the passphrase.

=== Step 2: Copy SSH Public Key to Managed Host(s)

You need to copy your Control Node's public SSH key (`~/.ssh/id_rsa.pub`) to the `authorized_keys` file in the `~/.ssh` directory of the user on each Managed Host that Ansible will connect as.

The easiest way to do this is using the `ssh-copy-id` command:
```bash
$ ssh-copy-id user@MANAGED_HOST_IP_OR_HOSTNAME
```
*   Replace `user` with the actual username on the Managed Host that Ansible will connect as (this user must have `sudo` privileges).
*   Replace `MANAGED_HOST_IP_OR_HOSTNAME` with the Managed Host's IP address or hostname.

You will be prompted to enter the Managed Host user's password *once* during this process. `ssh-copy-id` handles creating the `~/.ssh` directory and setting correct permissions if they don't exist.

.Alternative: Manual Key Copy
If `ssh-copy-id` is not available or you prefer to do it manually:
```bash
$ cat ~/.ssh/id_rsa.pub | ssh user@MANAGED_HOST_IP_OR_HOSTNAME "mkdir -p ~/.ssh && chmod 700 ~/.ssh && cat >> ~/.ssh/authorized_keys && chmod 600 ~/.ssh/authorized_keys"
```
You will be prompted for the password of `user` on `MANAGED_HOST_IP_OR_HOSTNAME`.

.Verification
After copying the key, try to SSH into the Managed Host from the Control Node. You should be able to connect without a password prompt (unless you set a passphrase for your SSH key, in which case you'd be prompted for that passphrase).
```bash
$ ssh user@MANAGED_HOST_IP_OR_HOSTNAME
```
If successful, type `exit` to return to your Control Node.

[[ansible-inventory]]
== Configuring the Ansible Inventory

The inventory file is a crucial component in Ansible. It's where you define your Managed Hosts, organize them into groups, and specify connection variables. By default, Ansible looks for `/etc/ansible/hosts`, but it's best practice to create project-specific inventory files.

=== Step 1: Create an Inventory File

Let's create a dedicated directory for our Ansible lab files and then an inventory file within it.

```bash
$ mkdir -p ~/ansible_lab
$ cd ~/ansible_lab
$ nano inventory.ini # or your preferred text editor like `vi`
```
Add the following content to `inventory.ini`, replacing `MANAGED_HOST_IP_OR_HOSTNAME` with your actual managed host's details and `user` with your SSH user:

```ini
[webservers]
managed_host_1 ansible_host=MANAGED_HOST_IP_OR_HOSTNAME ansible_user=user

[all:vars]
ansible_python_interpreter=/usr/bin/python3
```

.Explanation of Inventory Sections and Variables:
*   `[webservers]`: This defines a *host group* named `webservers`. You can group hosts logically (e.g., `databases`, `monitoring`, `dev_servers`).
*   `managed_host_1`: This is an arbitrary *alias* (a friendly name) for your managed host within Ansible. You'll use this alias or the group name when running commands.
*   `ansible_host=MANAGED_HOST_IP_OR_HOSTNAME`: This is a *host variable* that tells Ansible the actual IP address or hostname to connect to.
*   `ansible_user=user`: This is another *host variable* that specifies the username Ansible should use to connect via SSH to `managed_host_1`. This user *must* have `sudo` privileges on the Managed Host.
*   `[all:vars]`: This is a special group that defines *group variables* which apply to *all* hosts in the inventory.
*   `ansible_python_interpreter=/usr/bin/python3`: This explicitly tells Ansible which Python interpreter to use on the Managed Hosts. While Ansible is often good at discovering this, explicitly setting it can prevent potential issues, especially in environments with multiple Python versions.

[[test-connectivity]]
== Testing Connectivity with Ansible Ad-hoc Commands

With the Control Node, Managed Host, SSH keys, and inventory all configured, it's time to test if Ansible can successfully communicate with your Managed Host using an ad-hoc command. The `ping` module is perfect for this.

```bash
$ ansible -i inventory.ini webservers -m ping
```

.Explanation of the command:
*   `ansible`: The main command-line tool for running ad-hoc commands.
*   `-i inventory.ini`: Specifies to use your custom `inventory.ini` file. If you placed your hosts in `/etc/ansible/hosts`, you could omit this.
*   `webservers`: This targets the *host group* named `webservers` as defined in your inventory file.
*   `-m ping`: This specifies to use the `ping` *module*. The Ansible `ping` module is not an ICMP ping; instead, it tests if Ansible can connect to the managed host, successfully execute a small Python script, and receive a response.

.Expected Output:
If everything is configured correctly, you should see output similar to this:
```json
managed_host_1 | SUCCESS => {
    "ansible_facts": {
        "discovered_interpreter_python": "/usr/bin/python3"
    },
    "changed": false,
    "ping": "pong"
}
```
The `SUCCESS => {"ping": "pong"}` message indicates that your Control Node can successfully connect to and execute commands on your Managed Host. Congratulations!

[[troubleshooting-connectivity]]
== Troubleshooting Connectivity

If `ansible -m ping` fails, review the following common issues:

*   **SSH Key Not Copied**:
    *   **Symptom**: "Permission denied (publickey,password)."
    *   **Solution**: Double-check that your public SSH key from the Control Node (`~/.ssh/id_rsa.pub`) is correctly copied to `~/.ssh/authorized_keys` on the Managed Host for the user specified by `ansible_user`. Ensure file permissions are correct (`chmod 700 ~/.ssh` and `chmod 600 ~/.ssh/authorized_keys` on the Managed Host).
*   **Firewall Blocking SSH**:
    *   **Symptom**: "Connection timed out" or "No route to host."
    *   **Solution**: Ensure the firewall on your Managed Host (e.g., `ufw` on Ubuntu, `firewalld` on CentOS/RHEL) is not blocking port 22 (SSH).
        *   _Ubuntu_: `sudo ufw allow ssh` or `sudo ufw allow 22/tcp`
        *   _CentOS/RHEL_: `sudo firewall-cmd --permanent --add-service=ssh && sudo firewall-cmd --reload`
*   **Incorrect `ansible_user`**:
    *   **Symptom**: "Failed to connect to the host via SSH: Permission denied."
    *   **Solution**: Verify that the `ansible_user` specified in your `inventory.ini` exists on the Managed Host and has `sudo` privileges.
*   **Python Interpreter Issues**:
    *   **Symptom**: "Error while attempting to run Python on the remote host."
    *   **Solution**: Ensure Python 3 is installed on the Managed Host and that the `ansible_python_interpreter` path in your `inventory.ini` is correct (e.g., `/usr/bin/python3`).
*   **SSH Connectivity Test**:
    *   **Symptom**: `ssh user@MANAGED_HOST_IP_OR_HOSTNAME` from the Control Node also fails.
    *   **Solution**: If direct SSH fails, Ansible will also fail. Resolve the underlying SSH connectivity issue first (e.g., network connectivity, SSH server not running, incorrect credentials).
*   **Host Key Verification Failed**:
    *   **Symptom**: "Host key verification failed."
    *   **Solution**: This usually means the Managed Host's SSH key has changed or is incorrect in your Control Node's `~/.ssh/known_hosts` file. You might need to remove the relevant entry from `~/.ssh/known_hosts` on the Control Node.

[[hands-on-lab-setup-ansible-environment]]
== Hands-on Lab: Setting Up Your First Ansible Environment

This hands-on lab will guide you through the complete process of setting up a basic Ansible Control Node and one Managed Host using two Ubuntu Server 22.04 LTS virtual machines.

=== Lab Scenario

You have provisioned two fresh Ubuntu Server 22.04 LTS VMs with the following assumed details:

*   **Control Node VM**: `ansible-control` with IP address `192.168.1.100`
*   **Managed Host VM**: `ansible-managed-01` with IP address `192.168.1.101`

Your goal is to:
1.  Install Ansible on the `ansible-control` VM.
2.  Prepare `ansible-managed-01` for Ansible management.
3.  Establish secure SSH key-based authentication from the Control Node to the Managed Host.
4.  Create an Ansible inventory file.
5.  Verify successful connectivity using Ansible's `ping` module.

=== Step-by-Step Instructions

*   **Pre-lab Setup (outside Ansible configuration)**:
    *   Ensure both `ansible-control` and `ansible-managed-01` VMs are running.
    *   Confirm you can SSH into both VMs independently using a password (e.g., `ssh ubuntu@192.168.1.100` and `ssh ubuntu@192.168.1.101`). The default user on Ubuntu is often `ubuntu`.
    *   Verify both VMs have internet access.

==== On the `ansible-control` (Control Node - `192.168.1.100`)

1.  **Install Ansible**:
    ```bash
    $ sudo apt update
    $ sudo apt install software-properties-common -y
    $ sudo add-apt-repository --yes --update ppa:ansible/ansible
    $ sudo apt install ansible -y
    ```
2.  **Verify Ansible Installation**:
    ```bash
    $ ansible --version
    ```
    Confirm that the Ansible version information is displayed.
3.  **Generate SSH Key Pair**:
    We'll generate a key without a passphrase for convenience in this lab.
    ```bash
    $ ssh-keygen -t rsa -b 4096 -N "" -f ~/.ssh/id_rsa
    ```
    This command generates a 4096-bit RSA key, saves it to the default location (`~/.ssh/id_rsa`), and uses an empty passphrase.
4.  **Create Ansible Lab Directory**:
    ```bash
    $ mkdir -p ~/ansible_lab
    $ cd ~/ansible_lab
    ```

==== On the `ansible-managed-01` (Managed Host - `192.168.1.101`)

1.  **Ensure SSH Server is Installed and Running**:
    ```bash
    $ sudo apt update
    $ sudo apt install openssh-server -y
    $ sudo systemctl enable --now ssh
    ```
    Verify it's active: `sudo systemctl status ssh`
2.  **Ensure Python3 is Installed**:
    ```bash
    $ sudo apt update
    $ sudo apt install python3 -y
    ```
    Ubuntu Server typically has Python 3 pre-installed, but it's good practice to ensure it's there.

==== Back on the `ansible-control` (Control Node - `192.168.1.100`)

1.  **Copy SSH Public Key to `ansible-managed-01`**:
    We'll use the `ubuntu` user on the managed host. You will be prompted for the `ubuntu` user's password on `192.168.1.101` *once*.
    ```bash
    $ ssh-copy-id ubuntu@192.168.1.101
    ```
    After successful copying, test SSH connectivity without a password:
    ```bash
    $ ssh ubuntu@192.168.1.101
    ```
    You should connect directly without a password prompt. Type `exit` to return to your Control Node.
2.  **Create Ansible Inventory File**:
    Ensure you are in the `~/ansible_lab` directory.
    ```bash
    $ nano inventory.ini
    ```
    Add the following content to the file:
    ```ini
    [webservers]
    ansible-managed-01 ansible_host=192.168.1.101 ansible_user=ubuntu

    [all:vars]
    ansible_python_interpreter=/usr/bin/python3
    ```
    Save the file and exit your text editor (e.g., Ctrl+X, Y, Enter for Nano).
3.  **Test Connectivity with Ansible**:
    Execute the `ansible ping` command, specifying your custom inventory file and targeting the `webservers` group:
    ```bash
    $ ansible -i inventory.ini webservers -m ping
    ```
    You should see output similar to this:
    ```json
    ansible-managed-01 | SUCCESS => {
        "ansible_facts": {
            "discovered_interpreter_python": "/usr/bin/python3"
        },
        "changed": false,
        "ping": "pong"
    }
    ```

Congratulations! You have successfully set up your Ansible Control Node and a Managed Host, established secure communication, and verified connectivity. You are now ready to begin exploring Ansible's powerful automation capabilities!